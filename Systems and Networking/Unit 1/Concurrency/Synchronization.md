# Synchronization

Even though processes and threads cooperate to reach a common goal, each one of them (usually) executes its task by itself, with no known state of the other threads; executing threads with no logic regulation could bring bugs and problems to any program.

> [!example] Problem Example
> Take the case where a thread is trying to count the number of elements in a linked list.
> 
> While it's in the midst of counting, another thread adds a new element at the start of the list. The total count should have been increased by one, but the thread that counts has no way of knowing that, so the total count will have a missing element.

Often, in multi-threading programs, there are some *critical sections* where it is important that the section isn't disturbed by actions of other threads. To ensure this, we need to **synchronize** the threads so that they act properly.

Any type of synchronization must satisfy three properties,

- **Mutual Exclusion:** only one process/thread at a time may execute the critical section;
- **Liveness:** if any process/thread wants to get in the critical section when nobody is executing it, then it must be able to do so;
- **Bounded Waiting:** a process/thread requesting access to the critical access will eventually get a turn and there must be a limit to how many others can go first.

## Locks

Only one lock exists for critical section. As the word implies, whenever a thread gets to a critical section it *locks* it (*acquires the lock*), and the current thread is the only one that can execute and *unlock* (*release the lock*) the section. If the thread find the section *locked*, then the thread has to wait for the lock.

The lock policy implements two atomic primitives:

- `Lock.acquire()` - Wait until the lock is free, then grab it;
- `Lock.release()` - Unlock and wake up any thread waiting in `acquire()`.

> [!tip] When using a Lock
> - Always acquire the lock *before* accessing shared data;
> - Always release the lock *after* finishing with shared data;

#### Implementing Locks by disabling interrupts

By disabling/enabling interrupts when acquiring/releasing a lock, the current thread could execute the entire critical section while the other threads wait, assuming a single-core architecture. Beware, that the thread holding the lock cannot go into a *waiting* state, otherwise interrupts wouldn't be enabled again.

On a multi-core, though, the technique becomes unfeasible, because disabling interrupts for all processes and threads would, for sure, make things not work as intended. Moreover, the overhead generated by calling the primitives needed to manage interrupts isn't small.

#### Implementing Locks by atomic instructions

> [!example] The problem
> Assume two threads $t_1, t_2$ want to acquire the lock, so $t_1$ checks if the lock is free; $t_1$ reads the value, sees that the lock is free and begins acquiring it (it doesn't mark the lock as acquired yet).
> 
> Meanwhile, there's a context switch, $t_2$ sees the lock as free and acquires it (marks it as acquires). Another context switch follows and $t_1$, which knew that the lock was free, acquires the lock.
> 
> This situation is a bug, both threads saw the lock as free and acquired it. The reasons this happened is because reading and writing memory are two separated operations.

To solve the problem, the only thing needed is an *atomic instruction* (execution is ensured from start to finish) that lets the thread check that the lock is free and then mark it as acquired. Most architectures have a `test&set` instruction, which reads the memory location and immediately sets it to `1`.

The `test&set` instruction can be used to implement locks:
- if it reads `0`, then the lock is free, the thread can acquire it;
- if it reads `1`, then the lock isn't free, the thread can be put to sleep.

The value can always be set to `1`, because:
- if it reads `0`, then the thread is acquiring the lock, so it'd need to set it as acquired;
- if it reads `1`, then there's no problem.

## Semaphores

Semaphores are a generalization of synchronization like locks, but permit more than one thread to execute a single critical section.

If a semaphore permits just one thread then it's called *binary semaphore*, otherwise if it permits more than one thread (but less than a fixed number) then it's called *counting semaphore*.

Semaphores can be used for the following synchronization applications:
- Ensure mutually exclusion like locks (binary semaphore);
- Ensure limited access to certain resources (counting semaphores);
- Enforce scheduling constraints so as to execute threads according to some order.

TK semaphore methods

## Monitors

A monitor is a construct implemented by some programming languages (e.g. Java, C++) that controls access to shared data. The language provides some syntax to implement logic synchronizations, the actual synchronization (primitives/code) is added at compile time by the compiler.

Formally, a monitor defines a lock and zero or more condition variables for managing concurrent access to shared data. Using the lock guarantees mutual exclusion at any time.

> [!info] Synchronized
> Usually, monitors use the `synchronized` keyword to mark a code block as a critical section. When entering the critical sections, compilers automatically try to acquire the lock, waiting if necessary, and release it when leaving the section.


Condition variables, as the name implies, are variables that let threads wait for a certain condition before resuming execution of a critical section. Condition variables define some methods:
- `wait()`, give up the lock and wait inside the critical section;
- `notify()`, wake up a thread waiting inside the critical section;
- `notifyAll()`, wake up any thread waiting inside the critical section (only one will acquire the lock).

> [!tip] Semaphores vs Conditional Variables
> Semaphores and conditional variables may have the same methods, but their meanings differ.
> 
> | **Method** | **Semaphore** | **Conditional Variable** |
> | --- | --- | --- |
> | `wait()` | Wait to enter the critical section | Give up the lock and wait for a condition |
> | `signal/notify()` | Tell a waiting thread that access is available | Tell a waiting thread that something changed | 

> [!abstract] Mesa vs Hoare Monitors
> There are two types of monitors,
> - **Mesa:** returning from `wait()` is only a hint that something changed, the conditional variable must be checked again (in a `while` loop);
> - **Hoare:** returning from `wait()` guarantees that the conditional variable holds true, no need to check again (it's just an `if`).
> 
> *Mesa* is the most implemented one, while *Hoare* is the most theorical one.
